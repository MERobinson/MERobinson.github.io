[
["index.html", "Introduction to RNAseq Preface Contact", " Introduction to RNAseq Mark Robinson 2017-09-12 Preface The purpose of this tutorial is to introduce bioinformatics to complete beginners in a practical and accessible way. We’ll quickly cover setup, basic R scripting, data formats, qc, read alignment, quantification and visualistion. This site will remain active if you want to go through it at your own pace and I’m planning to continue developing it to provide further depth and introduce other bioinformatics topics in the future. Hopefully this will prove a useful resource for the department, if you have any ideas/requests let me know! Contact Any questions drop me an email at my imperial address - m.robinson@ic.ac.uk "],
["01.1_setup.html", "1 System Setup", " 1 System Setup For the current tutorial we’ll be using R. R is a statistical programming language commonly used in bioinformatics. R can be run from the command line but here we’ll be using an interface - refered to as an integrated development environment (IDE) - called RStudio. Before we start we need to make sure R, RStudio and some extra packages within R are installed. Follow the installation instructions for your operating system below to setup everything you need for the tutorial. 1.0.1 R For Mac OS X: Go to CRAN and download the instalation package appropriate for your OS and simply follow the instructions. For Windows: Go here -&gt; ‘Download R for Windows’ -&gt; ‘base’ -&gt; ‘Download R3.4.1 for Windows’. The installer will take you through setup. For Ubuntu: Through the software center - just search for r-base and install. At the command line: sudo apt-get update sudo apt-get install r-base 1.0.2 RStudio To get RStudio simply go here, download the installer appropriate for your system and follow the instructions. 1.0.3 Download Course Materials I’ve created a small set of sample data to use in the analysis that we need to download - go to my github -&gt; click the Clone or download button in the top right -&gt; select Download ZIP. Once finished downloading unzip it somewhere sensible. Done. "],
["01.2_overview.html", "2 RNA-seq Overview", " 2 RNA-seq Overview Figure 2.1: Overview of RNA-seq analysis 2.0.1 Experimental Design Experimental design can have a major impact on final results and very much depends on the aims of the experiment and system under investigation. It’s therefore impossible to give ‘best-practises’ guidelines but some general consderations are highlighted below: rRNA removal: rRNA accounts for ~90% of RNA, so needs to be removed - either by poly(A) selection or rRNA depletion Poly(A) requires higher RNA integrity and a larger input amount of RNA rRNA depletion might therefore be preferable for rare/degraded samples, and for looking at ncRNA (&amp; bacterial) Novel transcript discovery &amp; differential isoform usage: Strand-specificity is important for differentiating overlapping and antisense transcripts Paired end (PE) and 100bp or longer reads are also recommended Greater sequencing depth Differential gene expression: A larger quantity of short SE reads would be preferable if only the differential usage of known genes is being studied If only interested in highly expressed genes, ~5 million (M) reads may be sufficient Up to 100 M may be required for accurate quantification of lowly expressed transcripts For a standard exploratory analysis of DGE I’d personally aim for ~15-30 M reads for a mammalian genome Replicate number: Largely depends on biological variability and experimental practices The sequencing procedure itself has minimal impact 3 replicates is the minimum for statistical inference, although many studies still get away with 2 Increasing the number of replicates often provides greater statistical power than increasing read depth "],
["01.3_R_basics.html", "3 R basics", " 3 R basics To run analyses in R you’re going to need to know a few basic concepts about scripting/programming and some simple R commands. 3.0.1 RStudio Interface Firstly, open RStudio from your applications. The RStudio interface should look something like this: Figure 3.1: The RStudio interface Theres three main pane areas here: Left: This is the Console - the place where you input commands Upper right: contains Environment and History tabs, but you don’t need to worry about these just yet. Lower right: This pane has a few useful tabs: Files : a simple file explorer - lets you see and open files on your system Plots : this is where graphics are shown when you create them Packages : just a list of available R packages to load Help : here you can find helpful documentation on using R 3.0.2 Working Directory In the files window, create a new folder for the current analysis and enter it. The R session has a position in your file system - this is called the working directory. This is where all files will be loaded from or saved to by default. You can change the working directory by going to the Session menu -&gt; Set Working Directory -&gt; Choose Directory. This opens a file browser - choose the new folder we just made. 3.0.3 Programming languages Coding is essentially just passing commands to your computer. Commands are written in one of many programming languages which can then be translated into a machine-readable format. Many programming languages exist and which is best to use depends on the task. Some common languages in bioinformatics are: Bash : Bash (and other shell scripting languages) are used to interact with the main console/terminal - often refered to as the command line. It’s simple and pretty much essential to know to let you perform basic tasks like moving files and running programs at the command line. R : R is a slightly unusual language as it was developed by statisticians not programmers but this does mean it’s well equipped for performing statistical analyses. C : C was one of the first major programming languages and still one of the most widely used in the programming world, however it’s less abstracted than many, and therefore more difficult to write but faster to run. Good for serious algorithm-development but probably less use for the average applied bioinformatician. Python : Python is a good in between - fast enough to write some of your own quick programs but easy enough to write to use in standard downstream analysis too. Python is one of the most popular languages in bioinformatics. Perl : similar to python in it’s level of abstraction but maybe falling out of fashion a bit. Here we’ll be doing everything in R just to make it easier, but if anyones actually planning on doing their own analyses I’d recommend learning some basic Bash also - I’ll add some links to the resources page. 3.0.4 Coding Concepts There’s nothing difficult about coding, but can seem intimidating at first due to the unfamiliar terminology and concepts, so lets just run through a few basic things first. Like any language programming languages have grammar rules (called syntax) which need to be followed - capitilisation, commas, brackets etc. all have special meaning and if you add a capital or comma in the wrong place it might stop making sense to the computer and result in an error. So be aware of what you type. 3.0.4.1 Assigning Variables Variables are just objects you can create to hold information - just make up a name and tell it what to hold. The command below creates a variable called freddie and assigns it the value 1. Copy it to your R console and press enter to run it. freddie &lt;- 1 Now you can recall that value whenever you want by just giving the name: freddie R won’t like some variable names - it might give you an error if e.g. you try to use a name starting with a number. It’s generally best to stick to letters, underscores and periods. The ‘&lt;-’ in the first command is called an operator - it’s just a symbol that performs a specific function, just like a mathematic operator. In fact you can use most common mathematical operators in R too: freddie &lt;- 1 + 1 freddie &lt;- 2 * 5 You can use the values stored in variables inside operations: freddie &lt;- freddie / 2 The stored data doesn’t need to be numeric - for instance we could store a list of words: my_favourite_reptiles &lt;- list(&quot;croc&quot;,&quot;gator&quot;,&quot;KOMODO DRAGON!&quot;) 3.0.4.2 Functions &amp; Arguments Functions are kind of like mini-programs, they’re just a pre-defined series of commands run every time you call them. Using functions written by other people makes using R a lot easier - whatever you need to do, someone else has probably already written a function for it! There’s some data pre-existing in R that you can just mess around with to test things out, for instance, lets try looking at some plant data saved in a variable called iris: iris This should have printed 150 lines of data to your console, but that’s a bit more information than we really wanted. It would be useful to look just at the first few lines, luckily there’s a function for that! try using the head function: head(iris) Sweet! There’s lots of functions out there but you always call them in the same way - by typing the function name followed by curly brackets/parantheses. The things you put inside the brackets are called arguments - for instance in the last call to head we gave one argument - the iris object. Every function has different arguments, some required and some optional. To find out what arguments a function wants you can look at the help page for that function by typing a question mark in front of the function name: ?head You can see from the help page that in addition to the object to look at, there’s an ‘n’ argument to head which lets you control how many rows to print. Lets try it: head(iris, n = 10) head(iris, 15) Note that you can give arguments by name e.g. n = 10 or leave out the name and just give them in the order listed in the help documentation. "],
["01.4_qc.html", "4 Quality Control", " 4 Quality Control The first important step once you have your raw FASTQ data is to check the quality of the reads. I’d actually normally do this step with FASTQC - which is the standard tool for FASTQ QC and can be run either as a desktop application or at the command line. For now we’ll stick with R though. There are a few packages in R that you can use for this: ShortRead, Rqc, SeqTools, Rsubread and others. We’ll use ShortRead. 4.0.1 Setup Bioinformatics R packages are available from 2 main repositories - CRAN which is the general R site, and Bioconductor - which is specific for genomics packages. ShortRead is a Bioconductor package, so to install we can use the biocLite installer: source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite(&quot;ShortRead&quot;) Then we load the package with library so that we can access it’s functions: library(&quot;ShortRead&quot;) You only need to install packages once, but you need to load them every time you open a new session. For convenience you can wrap this in a conditional statement to check if the package is already installed, and if not install then load it. if (!suppressWarnings(require(ShortRead))) { source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;ShortRead&quot;) library(ShortRead) } 4.0.2 FASTQ Data You don’t actually need to read the FASTQ files into R to run the QC but lets just take a quick look to familiarise ourselves with what FASTQ files contain. First, find the FASTQ files list.files function with the following arguments: path tells it where to search - in this case, the fastq folder full.names tell it whether to include the directory name as well, which we need so we’ll set it to TRUE fastq_files &lt;- list.files(path = &quot;fastq&quot;, full.names = TRUE) Now lets read one of the files into R with the readFastq function. Normally you wouldn’t want to read a full FASTQ file into R becuase they’re big and you’d quickly run out of memory, but the files we’re using are just one chromosome so it’s all good. To get just the first file from the list we index it by adding the [1]: fastq_data &lt;- readFastq(fastq_files[1]) If you just type the variable name you can see some basic info - the class of the object, the number of reads and the number of cycles (i.e. read length): fastq_data ## class: ShortReadQ ## length: 1454981 reads; width: 100 cycles Take a look at some reads with the sread function: head(sread(fastq_data)) ## A DNAStringSet instance of length 6 ## width seq ## [1] 100 TTTACAGCCAAGTATTTAAAATGTTTTGTCA...TTAAAACTTTAACTTCTTAAAAGACAAAAAA ## [2] 100 ACTGTGTCTTAAGACTCCGCCCCACAGAAGC...TGAGAAAAATGACTTTACAATAATGTTTTAG ## [3] 100 TCTCTTTAGACGTTTGCTAACTTTCTTCAGG...GCTGTCTGTATTATACAATGTGTACTTGAAA ## [4] 100 GAGATATAAGAGCTGAGTGGCCAGCGACCTA...CTAGTCCTGCAAGCGCCTGGGCAATAACCAC ## [5] 100 CAGCGACCTATTGCCTAAGCATAGATATATC...CAATAACCACCTTGTCTCTCTTAGTTTGGGC ## [6] 100 GGGGACCAAAGCCTTAAAGACGCCTCCAAGG...GAAGTCGTCCGAGGTGGAGAATCTGTGCCCA As you can see, this is just a series of called bases for each read. You can also view base qualities with the quality function: head(quality(fastq_data)) ## class: FastqQuality ## quality: ## A BStringSet instance of length 6 ## width seq ## [1] 100 CCCFFFFFHHHGHIIJJJJJJJJHJJJJJJI...JJIIIGCGIJJIIIJJHHFHHHHFFFF@CDD ## [2] 100 @@CFFDDDHDFFHBGIJGI@GHHCHJJGDGH...&gt;AAC3@&gt;&lt;BBC:@ACC&gt;@CCCDCEADCCDA? ## [3] 100 CCCFFFFFHGHHHJJJJJJGIIJJJJJJJJJ...HHHFFF@EFFEEFFEEEDDD(-&gt;BDDEDDDD ## [4] 100 CCCFFFFFHHHHHJJJJGIJJJJJJJJIJIJ...FFFFEE&gt;CEEEDDDDDDDDDDDDDDDDDDDD ## [5] 100 CCCFFFFFHHHHHJJJIJJIJJJJJIJJJJJ...FEDEEEDDDDDDDDDDDDDDDDCDDDEDDBD ## [6] 100 CCCFFFFFGHHHHJJJJJJJJJIJJJJJJJI...DDDDAC8&lt;@BDDDD0&lt;BDDDDDDDCCDDDDD If the base quality scores printed by the above command look like nonsense to you, thats because they kind of are! 4.0.3 Base Quality Scores Each base is given a quality score to indicate the probability of the base call being wrong. The probablity is scaled with the equation below to produce the Phred quality score: \\[ Q = -10 log_{10} P \\] And if you hate maths: “Ten times the number of zeros you need to wack in front of a 1 to get the probability” So the higher the Phred score the better! In FASTQ format the Phred quality score is then encoded by a character - there’s some odd logic to doing this but I wouldn’t sweat it, most tools will convert it back to the Phred score for you. Examples: Table 4.1: Converting base quality scores. Phred Quality Score Probability of error Base call accuracy ASCII encoding 10 0.1 (1 in 10) 90% + 20 0.01 (1 in 100) 99% 5 30 0.001 (1 in 1,000) 99.9% ? 40 0.0001 (1 in 10,000) 99.99% I 4.0.4 QC Report To generate the QC metrics for all the FASTQ all you need to do is run the qa command on the fastq directory: qa_summary &lt;- qa(dirPath = &quot;fastq&quot;, type=&quot;fastq&quot;) You can then view a report in a web-browser by running: browseURL(report(qa_summary)) The report gives some advice about what you’d expect to see in high/poor quality data, it’s worth taking a read. There some additional common issues worth being aware of too. Common issues: Sequence quality degrades with increasing read length so you’ll often see a drop towards the end of reads - particularly for longer reads A temporary drop in quality in the middle of reads could indicate a run issue such as bubbles running through the flow cell Over-represented sequences - such as contaminants or spike-ins can bias base composition, GC content and duplication Base composition bias in the first ~12bp - this is often observed due to the fact that random hexamer priming isn’t really random, but doesn’t appear to have an effect downstream and can generally just be ignored. Duplication - RNA-seq libraries will often have high degrees of duplication due to highly abundant transcripts and potentially spike-ins, it’s on the whole best not to remove duplicates in RNA-seq. We can see one of these common issues in the report - both reads 1 and 2 show a temporary drop in quality at around cycle 80 and 45 respectively. It’s possible to mask the bases from these cycles across reads, however for the tutorial we’ll just leave them as they are. 4.0.5 Next Step How best to address QC issues is strongly influenced by your choice of alignment tool. For instance if you see low base quality towards the ends of your reads trimming would be advisable for non-truncating tools such as Tophat but might not be necessary for aligners such as STAR which can soft-clip unaligned sections. Tools also have differing levels of mis-match tolerance. This review is a bit outdated but still worth a read. If you’re happy with the quality of the raw reads the next step is to determine which gene/transcript each short read originated from. "],
["01.5_alignment.html", "5 Read Alignment", " 5 Read Alignment Figure 5.1: Overview of RNA-seq analysis There are three main approaches to aligning reads to the genome: Map to the genome: This is the standard traditional approach Complicated by the size of the genomes, the millions of reads sequenced &amp; polymorphism Unlike DNA-based sequence techniques RNA-seq also needs to account for splicing Identification of splice sites decreases the accuracy of mapping Allows identification of novel transcripts, mutations and gene fusions Doesn’t require Map to the transcriptome: Reduces amount of sequence you need to search against significantly Eleviates issue of identifying splice sites Much faster Requires well annotated transcriptome Doesn’t allow identification of novel transcripts de novo transcriptome assembly: Attempts to reconstruct transcripts directly from short reads Doesn’t required reference genome/transcriptome Assuming you’re working on a mammalian genome the key determining factor here is probably whether you’re interested in novel transcripts, mutations/SNPs or gene fusions. If you just want to quanitify known transcripts the best choice is likely transcriptome mapping. This is especially true since the development of the new alignment-independent algorithms. Alignment-independent or pseudo-alignment algorithms basically determine the transcript a read originates from based on sequence/kmer composition without needing to determine the exact position, making them extremely fast. Furthermore, although they’re still new and not comprehensively tested, they appear to be more accurate and can normalise for differences in transcript length between samples. The tximport package is useful for reading results into R. Of course you aren’t restricted to using one or the other - my recommended approach would be to use a splice-aware alignment tool for transcript-discovery together with an alignment-independent tool for transcript-quantification. My current choice would be STAR together with Salmon. The major drawback of STAR is that it requires a LOT of memory - you’re probably gonna need &gt;30 Gb of Ram, meaning it’s not really an option for many beginners. Another good option might be HISAT2 which largely replaces the popular but slow (and not great) Tophat2. For a list of commonly used tools see the resources section. 5.0.1 Current Analysis Unfortunately most of these tools aren’t available in R, and you’d need to learn a little bit of shell scripting if you wanted to use them at the command line. For now, we’ll use GSNAP - a splice-aware aligner that has an R-wrapper and performs pretty well comparative simulations. 5.0.2 Setup BSgenome packages contain information on whole genomes, SNPs and sometimes masks. This specific package is for Mus musculus mm10 genome. if (!suppressWarnings(require(BSgenome.Mmusculus.UCSC.mm10))) { source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;BSgenome.Mmusculus.UCSC.mm10&quot;) library(BSgenome.Mmusculus.UCSC.mm10) } TxDb packages contain annotation information for specific genome builds and database sources. This specific package is for UCSC knownGene annotations for the Mus musculus mm10 genome. if (!suppressWarnings(require(TxDb.Mmusculus.UCSC.mm10.knownGene))) { source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;TxDb.Mmusculus.UCSC.mm10.knownGene&quot;) library(TxDb.Mmusculus.UCSC.mm10.knownGene) } gmapR is a package to run GSNAP from R. if (!suppressWarnings(require(gmapR))) { source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;gmapR&quot;) library(gmapR) } 5.0.3 Creating Genome Index As with most alignment tools we first need to create an index of the reference genome, for this we’re using that mm10 sequence from the BSgenome package. mm10_genome &lt;- BSgenome.Mmusculus.UCSC.mm10 Normally you would just use this as the genome argument in the indexing but to speed things up we need to get just the sequence of chr10 from the BSgenome object into a usable format. You don’t really need to know whats going on here just run the following commands: mm10_chr10 &lt;- as(mm10_genome$chr10, &quot;DNAStringSet&quot;) names(mm10_chr10) &lt;- &quot;chr10&quot; Okay now we’re ready to create the index using the GmapGenome() function which takes the following arguments: genome = The sequence object to index name = a name to save the index as create = indicates whether to create a new index index &lt;- GmapGenome(genome = mm10_chr10, name = &quot;mm10_chr10&quot;, create = TRUE) Next we want known splice-site information to supplement the index with, we’ll get this from the knownGene TxDb. First load the txdb object, extract exons with the exonsBy() accessor function, then filter chromosomes to just get chr10 exons. txdb &lt;- TxDb.Mmusculus.UCSC.mm10.knownGene exons &lt;- exonsBy(txdb) chr10_exons &lt;- keepSeqlevels(exons, &quot;chr10&quot;) We then add this information to the index using the spliceSites() accessor. spliceSites(index, &quot;knownGene&quot;) &lt;- chr10_exons Ok all setup, alignment time! 5.0.4 Aligning Reads Alignment parameters are set as a simple list then passed to the mapping function. Most alignment tools have lots of parameters that you can tweak to alter the default behaviour. You can (usually) find documentation for all the options on the tools website. The parameters used here basically just set some penalties for indels and distant splice sites, and tell the tool to look for novel splice sites. One important consideration when setting stringency is how polymorphic you expect your samples to be compared with the reference transcriptome, obviously mouse samples will normally have much less variation from the reference than human samples. gsnap_param &lt;- GsnapParam(genome = index, novelsplicing = TRUE, splicing = &quot;knownGene&quot;, indel_penalty = 1L, distant_splice_penalty = 1L, clip_overlap = TRUE) Then we (would) just run the alignment like so: Even with just one chromosome this is still pretty slow (~25m) so rather than run this right now we’ll just load some pre-aligned data. gsnap_output &lt;- gsnap(input_a = fastq_files[[1]], input_b = fastq_files[[2]], params = gsnap_param) 5.0.5 Output Any alignment-based tools will produce as it’s main output a Sequence Alignment Map (SAM) file, or it’s binary equivalent BAM. SAM/BAM is the standard format for storing aligned short reads (and increasing unaligned reads too). See the formats "],
["01.6_read_counts.html", "6 Post-alignment", " 6 Post-alignment 6.0.1 Setup Just make sure the TxDb object is loaded again. if (!suppressWarnings(require(TxDb.Mmusculus.UCSC.mm10.knownGene))) { source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;TxDb.Mmusculus.UCSC.mm10.knownGene&quot;) library(TxDb.Mmusculus.UCSC.mm10.knownGene) } GenomicAlignments provides functions for storing, manipulating and counting short read alignments. if (!suppressWarnings(require(GenomicAlignments))) { source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;GenomicAlignments&quot;) library(GenomicAlignments) } 6.0.2 QC Tools: Picard Samtools RSeQC FASTQC Metrics: % mapped % multi-mapping duplication rate GC bias coverage bias replicate correlation 6.0.3 Count Reads Most differential expression analysis programs take as input raw counts of the number of reads mapping to each gene. It’s common to perform this step on the command line with HTseq-count. But we can just as simply do so in R. First extract exon locations from the txdb object again: exons &lt;- exonsBy(TxDb.Mmusculus.UCSC.mm10.knownGene) exons_chr10 &lt;- keepSeqlevels(exons, &quot;chr10&quot;) Then find the output bam files from alignment: bam_files &lt;- list.files(path = &quot;bam&quot;, full.names = T) names(bam_files) &lt;- c(&quot;BCR&quot;, &quot;EV&quot;) bam_files &lt;- BamFileList(bam_files, yieldSize=2000000) Finally we count reads using the summarizeOverlaps() function with the following arguments: features = regions to count reads over (the exons in this case) reads = bam files to count from mode = determines how reads are assigned to features - see docs singleEnd = indicates whether reads are SE ignore.strand = indicates if library is stranded fragments = whether to include unpaired reads se &lt;- summarizeOverlaps(features = exons_chr10, reads = bam_files, singleEnd = FALSE, ignore.strand = TRUE, fragments = TRUE) This produces a count matrix with one column per sample and one row per gene. The data is stored as a summarised experiment which can be subsequently used in differential expression analysis, e.g. with DESeq2 or limma. Examining the se object indicates the dimensions, what assay data is stored (counts), the rownames - representing entrez IDs, columns/conditions: se ## class: RangedSummarizedExperiment ## dim: 3252 2 ## metadata(0): ## assays(1): counts ## rownames(3252): 34554 34555 ... 37804 37805 ## rowData names(0): ## colnames(2): BCR EV ## colData names(0): Use assay() to access the counts: head(assay(se)) ## BCR EV ## 34554 0 0 ## 34555 0 0 ## 34556 0 0 ## 34557 0 0 ## 34558 0 0 ## 34559 0 0 We can sum the counts per samples with colSums(): colSums(assay(se)) ## BCR EV ## 143650 143289 Thats it! You’re now ready for downstream analysis and interpretation of results. "],
["02.0_resources.html", "7 Resources", " 7 Resources 7.0.1 Reviews RNA-seq best practices - Conesa et al., 2016. Genome Biology. Statistical methods for differential expression - Huang et al. 2015. Cancer Informatics. RNA-seq overview - Wang et al., 2009. Nature Reviews Genetics. Comparison of isoform quantification tools - Zhang et al., 2017. BMC Genomics. Comparison of spliced alignment tools - Engstrom et al., 2013. Nature Methods. 7.0.2 Tool papers STAR Sailfish kallisto Salmon 7.0.3 Tool websites STAR Tophat2 HISAT2 Salmon Kallisto Sailfish 7.0.4 Protocols Mapping read with STAR 7.0.5 Blog &amp; Forum Posts: 7.0.5.1 QC FASTQC duplication plot explanation 7.0.5.2 Aligners Comparing alignment-free and spliced alignment algorithms Unless one specifically requires transcript-level quantification, I would therefore always recommend using gene-level quantification From these simulations, it appears to be far better to use alignment-independent counting and aggregate to the gene level. 7.0.5.3 Normalisation Explanation of various normalisation methods 7.0.5.4 General Explanation of arguments for SRA-Tools fastq-dump "],
["03.0_formats.html", "8 Formats 8.1 SAM Format", " 8 Formats 8.1 SAM Format Full documentation can be found on the github page. There are two sections to SAM files: A Header section - which can store various meta-information. Header lines start with an **@** symbol Optional (but highly recommended) It’s good practice to store all salient information about sequencng, sample information and processing steps within the header DO NOT put important information only in the filename The alignment section - conatains 11 mandatory fields related to each read alignment. Note: individual reads may appear multiple times if multi-mapping Mandatory fields: QNAME - query template name (i.e. read name) FLAG - bitwise flag (explained here) RNAME - reference sequence name (chromosome it’s mapped) POS - 1-based left most mapping position (chromosome position) MAPQ - mapping quality (explained below) CIGAR - CIGAR string (explained below) RNEXT - reference name of the mate read TLEN - tempate length (length of original fragment - if PE) SEQ - segment sequence QUAL - base quality Following the mandatory fields, custom tags can be added Example - one SAM record: HWI-D00467:267:CBF3RANXX:7:2113:10878:30427 1024 chr1 10000 0 50M * 0 ATAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT /&lt;&lt;BBFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF MD:Z:50 PG:Z:MarkDuplicates.4 RG:Z:CBF3RANXX.7 NM:i:1 UQ:i:14 AS:i:50 XS:i:49 "]
]
