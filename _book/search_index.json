[
["index.html", "Introduction to RNAseq Preface Contact", " Introduction to RNAseq Mark Robinson 2017-09-11 Preface The purpose of this tutorial is to introduce bioinformatics to complete beginners in a practical and accessible way. We’ll quickly cover setup, basic R scripting, data formats, qc, read alignment, quantification and visualistion. This site will remain active if you want to go through it at your own pace and I’m planning to continue developing it to provide further depth and introduce other bioinformatics topics in the future. Hopefully this will prove a useful resource for the department, if you have any ideas/requests let me know! Contact Any questions drop me an email at my imperial address - m.robinson@ic.ac.uk "],
["01.1_overview.html", "1 RNA-seq Overview", " 1 RNA-seq Overview 1.0.1 Experimental Design Experimental design can have a major impact on final results and very much depends on the aims of the experiment and system under investigation. It’s therefore impossible to give ‘best-practises’ guidelines but some general consderations are highlighted below: rRNA removal: rRNA accounts for ~90% of RNA, so needs to be removed - either by poly(A) selection or rRNA depletion Poly(A) requires higher RNA integrity and a larger input amount of RNA rRNA depletion Novel transcript discovery &amp; differential isoform usage: Strand-specificity is important for differentiating overlapping and antisense transcripts Paired end (PE) and 100bp or longer reads are also recommended Greater sequencing depth Differential gene expression: A larger quantity of short SE reads would be preferable if only the differential usage of known genes is being studied If only interested in highly expressed genes, ~5 million (M) reads may be sufficient Up to 100 M may be required for accurate quantification of lowly expressed transcripts For a standard exploratory analysis of DGE I’d personally aim for ~15-30 M reads for a mammalian genome Replicate number: Largely depends on biological variability and experimental practices The sequencing procedure itself has minimal impact 3 replicates is the minimum for statistical inference, although many studies still get away with 2 Increasing the number of replicates often provides greater statistical power than increasing read depth "],
["01.2_setup.html", "2 System Setup", " 2 System Setup For the current tutorial we’ll be using R. R is a statistical programming language commonly used in bioinformatics. R can be run from the command line but here we’ll be using an interface - refered to as an integrated development environment (IDE) - called RStudio. Before we start we need to make sure R, RStudio and some extra packages within R are installed. Follow the installation instructions for your operating system below to setup everything you need for the tutorial. 2.0.1 R For Mac OS X: Go to CRAN and download the instalation package appropriate for your OS and simply follow the instructions. For Windows: Go here -&gt; ‘Download R for Windows’ -&gt; ‘base’ -&gt; ‘Download R3.4.1 for Windows’. The installer will take you through setup. For Ubuntu: Through the software center - just search for r-base and install. At the command line: sudo apt-get update sudo apt-get install r-base 2.0.2 RStudio To get RStudio simply go here, download the installer appropriate for your system and follow the instructions. "],
["01.3_R_basics.html", "3 R basics", " 3 R basics To run analyses in R you’re going to need to know a few basic concepts about scripting/programming and some simple R commands. 3.0.1 RStudio Interface Firstly, open RStudio from your applications. The RStudio interface should look something like this: (#fig:rstudio_interface)The RStudio interface Theres three main pane areas here: Left: This is the Console - the place where you input commands Upper right: contains Environment and History tabs, but you don’t need to worry about these just yet. Lower right: This pane has a few useful tabs: Files : a simple file explorer - lets you see and open files on your system Plots : this is where graphics are shown when you create them Packages : just a list of available R packages to load Help : here you can find helpful documentation on using R 3.0.2 Working Directory In the files window, create a new folder for the current analysis and enter it. The R session has a position in your file system - this is called the working directory. This is where all files will be loaded from or saved to by default. You can change the working directory by going to the Session menu -&gt; Set Working Directory -&gt; Choose Directory. This opens a file browser - choose the new folder we just made. 3.0.3 Programming languages Coding is essentially just passing commands to your computer. Commands are written in one of many programming languages which can then be translated into a machine-readable format. Many programming languages exist and which is best to use depends on the task. Some common languages in bioinformatics are: Bash : Bash (and other shell scripting languages) are used to interact with the main console/terminal - often refered to as the command line. It’s simple and pretty much essential to know to let you perform basic tasks like moving files and running programs at the command line. R : R is a slightly unusual language as it was developed by statisticians not programmers but this does mean it’s well equipped for performing statistical analyses. C : C was one of the first major programming languages and still one of the most widely used in the programming world, however it’s less abstracted than many, and therefore more difficult to write but faster to run. Good for serious algorithm-development but probably less use for the average applied bioinformatician. Python : Python is a good in between - fast enough to write some of your own quick programs but easy enough to write to use in standard downstream analysis too. Python is one of the most popular languages in bioinformatics. Perl : similar to python in it’s level of abstraction but maybe falling out of fashion a bit. Here we’ll be doing everything in R just to make it easier, but if anyones actually planning on doing their own analyses I’d recommend learning some basic Bash also - I’ll add some links to the resources page. 3.0.4 Coding Concepts There’s nothing difficult about coding, but can seem intimidating at first due to the unfamiliar terminology and concepts, so lets just run through a few basic things first. Like any language programming languages have grammar rules (called syntax) which need to be followed - capitilisation, commas, brackets etc. all have special meaning and if you add a capital or comma in the wrong place it might stop making sense to the computer and result in an error. So be aware of what you type. 3.0.4.1 Assigning Variables Variables are just objects you can create to hold information - just make up a name and tell it what to hold. The command below creates a variable called freddie and assigns it the value 1. Copy it to your R console and press enter to run it. freddie &lt;- 1 Now you can recall that value whenever you want by just giving the name: freddie R won’t like some variable names - it might give you an error if e.g. you try to use a name starting with a number. It’s generally best to stick to letters, underscores and periods. The ‘&lt;-’ in the first command is called an operator - it’s just a symbol that performs a specific function, just like a mathematic operator. In fact you can use most common mathematical operators in R too: freddie &lt;- 1 + 1 freddie &lt;- 2 * 5 You can use the values stored in variables inside operations: freddie &lt;- freddie / 2 The stored data doesn’t need to be numeric - for instance we could store a list of words: animal_noises &lt;- list(&quot;moo&quot;,&quot;baa&quot;,&quot;quack&quot;) 3.0.4.2 Functions &amp; Arguments Functions are kind of like mini-programs, they’re just a pre-defined series of commands run every time you call them. Using functions written by other people makes using R a lot easier - whatever you need to do, someone else has probably already written a function for it! There’s some data pre-existing in R that you can just mess around with to test things out, for instance, lets try looking at some plant data saved in a variable called iris: iris This should have printed 150 lines of data to your console, but that’s a bit more information than we really wanted. It would be useful to look just at the first few lines, luckily there’s a function for that! try using the head function: head(iris) Sweet! There’s lots of functions out there but you always call them in the same way - by typing the function name followed by curly brackets/parantheses. The things you put inside the brackets are called arguments - for instance in the last call to head we gave one argument - the iris object. Every function has different arguments, some required and some optional. To find out what arguments a function wants you can look at the help page for that function by typing a question mark in front of the function name: ?head You can see from the help page that in addition to the object to look at, there’s an ‘n’ argument to head which lets you control how many rows to print. Lets try it: head(iris, n = 10) head(iris, 15) Note that you can give arguments by name e.g. n = 10 or leave out the name and just give them in the order listed in the help documentation. "],
["01.4_qc.html", "4 Quality Control", " 4 Quality Control The first important step once you have your raw FASTQ data is to check the quality of the reads. I’d actually normally do this step with FASTQC - which is the standard tool for FASTQ QC and can be run either as a desktop application or at the command line. For now we’ll stick with R though. There are a few packages in R that you can use for this: ShortRead, Rqc, SeqTools, Rsubread and others. We’ll use ShortRead. 4.0.1 Setup Bioinformatics R packages are available from 2 main repositories - CRAN which is the general R site, and Bioconductor - which is specific for genomics packages. ShortRead is a Bioconductor package, so to install we can use the biocLite installer: source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite(&quot;ShortRead&quot;) Then we load the package with library so that we can access it’s functions: library(&quot;ShortRead&quot;) You only need to install packages once, but you need to load them every time you open a new session. For convenience you can wrap this in a conditional statement to check if the package is already installed, and if not install then load it. if (!suppressWarnings(require(ShortRead))) { source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;ShortRead&quot;) library(ShortRead) } 4.0.2 FASTQ Data You don’t actually need to read the FASTQ files into R to run the QC but lets just take a quick look to familiarise ourselves with what FASTQ files contain. First, find the FASTQ files list.files function with the following arguments: path tells it where to search - in this case, the fastq folder full.names tell it whether to include the directory name as well, which we need so we’ll set it to TRUE fastq_files &lt;- list.files(path = &quot;fastq&quot;, full.names = TRUE) Now lets read one of the files into R with the readFastq function. Normally you wouldn’t want to read a full FASTQ file into R becuase they’re big and you’d quickly run out of memory, but the files we’re using are just one chromosome so it’s all good. To get just the first file from the list we index it by adding the [1]: fastq_data &lt;- readFastq(fastq_files[1]) If you just type the variable name you can see some basic info - the class of the object, the number of reads and the number of cycles (i.e. read length): fastq_data ## class: ShortReadQ ## length: 1454981 reads; width: 100 cycles Take a look at some reads with the sread function: head(sread(fastq_data)) ## A DNAStringSet instance of length 6 ## width seq ## [1] 100 TTTACAGCCAAGTATTTAAAATGTTTTGTCA...TTAAAACTTTAACTTCTTAAAAGACAAAAAA ## [2] 100 ACTGTGTCTTAAGACTCCGCCCCACAGAAGC...TGAGAAAAATGACTTTACAATAATGTTTTAG ## [3] 100 TCTCTTTAGACGTTTGCTAACTTTCTTCAGG...GCTGTCTGTATTATACAATGTGTACTTGAAA ## [4] 100 GAGATATAAGAGCTGAGTGGCCAGCGACCTA...CTAGTCCTGCAAGCGCCTGGGCAATAACCAC ## [5] 100 CAGCGACCTATTGCCTAAGCATAGATATATC...CAATAACCACCTTGTCTCTCTTAGTTTGGGC ## [6] 100 GGGGACCAAAGCCTTAAAGACGCCTCCAAGG...GAAGTCGTCCGAGGTGGAGAATCTGTGCCCA As you can see, this is just a series of called bases for each read. You can also view base qualities with the quality function: head(quality(fastq_data)) ## class: FastqQuality ## quality: ## A BStringSet instance of length 6 ## width seq ## [1] 100 CCCFFFFFHHHGHIIJJJJJJJJHJJJJJJI...JJIIIGCGIJJIIIJJHHFHHHHFFFF@CDD ## [2] 100 @@CFFDDDHDFFHBGIJGI@GHHCHJJGDGH...&gt;AAC3@&gt;&lt;BBC:@ACC&gt;@CCCDCEADCCDA? ## [3] 100 CCCFFFFFHGHHHJJJJJJGIIJJJJJJJJJ...HHHFFF@EFFEEFFEEEDDD(-&gt;BDDEDDDD ## [4] 100 CCCFFFFFHHHHHJJJJGIJJJJJJJJIJIJ...FFFFEE&gt;CEEEDDDDDDDDDDDDDDDDDDDD ## [5] 100 CCCFFFFFHHHHHJJJIJJIJJJJJIJJJJJ...FEDEEEDDDDDDDDDDDDDDDDCDDDEDDBD ## [6] 100 CCCFFFFFGHHHHJJJJJJJJJIJJJJJJJI...DDDDAC8&lt;@BDDDD0&lt;BDDDDDDDCCDDDDD If the base quality scores printed by the above command look like nonsense to you, thats because they kind of are! 4.0.3 Base Quality Scores Each base is given a quality score to indicate the probability of the base call being wrong. The probablity is scaled with the equation below to produce the Phred quality score: \\[ Q = -10 log_{10} P \\] And if you hate maths: “Ten times the number of zeros you need to wack in front of a 1 to get the probability” So the higher the Phred score the better! In FASTQ format the Phred quality score is then encoded by a character - there’s some odd logic to doing this but I wouldn’t sweat it, most tools will convert it back to the Phred score for you. Examples: Table 4.1: Converting base quality scores. Phred Quality Score Probability of error Base call accuracy ASCII encoding 10 0.1 (1 in 10) 90% + 20 0.01 (1 in 100) 99% 5 30 0.001 (1 in 1,000) 99.9% ? 40 0.0001 (1 in 10,000) 99.99% I 4.0.4 QC Report To generate the QC metrics for all the FASTQ all you need to do is run the qa command on the fastq directory: qa_summary &lt;- qa(dirPath = &quot;fastq&quot;, type=&quot;fastq&quot;) You can then view a report in a web-browser by running: browseURL(report(qa_summary)) The report gives some advice about what you’d expect to see in high/poor quality data, it’s worth taking a read. There some additional common issues worth being aware of too. Common issues: Sequence quality degrades with increasing read length so you’ll often see a drop towards the end of reads - particularly for longer reads A temporary drop in quality in the middle of reads could indicate a run issue such as bubbles running through the flow cell Over-represented sequences - such as contaminants or spike-ins can bias base composition, GC content and duplication Base composition bias in the first ~12bp - this is often observed due to the fact that random hexamer priming isn’t really random, but doesn’t appear to have an effect downstream and can generally just be ignored. Duplication - RNA-seq libraries will often have high degrees of duplication due to highly abundant transcripts and potentially spike-ins, it’s on the whole best not to remove duplicates in RNA-seq. We can see one of these common issues in the report - both reads 1 and 2 show a temporary drop in quality at around cycle 80 and 45 respectively. It’s possible to mask the bases from these cycles across reads, however for the tutorial we’ll just leave them as they are. How best to address QC issues is strongly influenced by your choice of alignment tool. For instance if you see low base quality towards the ends of your reads trimming would be advisable for non-truncating aligners such as Tophat but might not be necessary for aligners such as STAR which can soft-clip unaligned sections. Tools also have differing levels of mis-match tolerance. This review is a bit outdated but still worth a read. "],
["01.5_alignment.html", "5 Read Alignment", " 5 Read Alignment The traditional approach to RNA-seq analysis is to first align reads against the reference genome, then count the number of reads per gene or transcript. The major challenge in RNA-seq read alignment is accounting for splicing. There’s two main ways to approach this: If the transcriptome of interest is well annotated you can simply use a standard short read aligner to map reads directly to the transcriptome If transcriptome annotation is poor or novel splicing/transcripts are of interest it’s better to go for spliced alignment algorithms A relatively new breed of algorithms allow alignment-free quantification of transcript abundance - and therefore tend to be much faster, and potentially more accurate. The major drawback being that alignment-free prevents identification of novel transcripts, gene-fusions, mutations, etc. My personal preference currently would be to use STAR for novel/fusion/mutation analyses together with Salmon or Kallisto for quantification. For a list of commonly used tools see the resources section. For this tutorial we’ll stick with the traditional spliced-alignment approach. We’ll be using the GSNAP algorithm via an R package. GSNAP is also available at the command line, and performs pretty well in comparative simulations. 5.0.1 Setup BSgenome packages contain information on whole genomes, SNPs and sometimes masks. This specific package is for Mus musculus mm10 genome. if (!suppressWarnings(require(BSgenome.Mmusculus.UCSC.mm10))) { source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;BSgenome.Mmusculus.UCSC.mm10&quot;) library(BSgenome.Mmusculus.UCSC.mm10) } TxDb packages contain annotation information for specific genome builds and database sources. This specific package is for UCSC knownGene annotations for the Mus musculus mm10 genome. if (!suppressWarnings(require(TxDb.Mmusculus.UCSC.mm10.knownGene))) { source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;TxDb.Mmusculus.UCSC.mm10.knownGene&quot;) library(TxDb.Mmusculus.UCSC.mm10.knownGene) } gmapR is a package to run GSNAP from R. if (!suppressWarnings(require(gmapR))) { source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;gmapR&quot;) library(gmapR) } 5.0.2 Creating Genome Index As with most alignment tools we first need to create an index of the reference genome, for this we’re using that mm10 sequence from the BSgenome package. mm10_genome &lt;- BSgenome.Mmusculus.UCSC.mm10 Normally you would just use this as the genome argument in the indexing but to speed things up we need to get just the sequence of chr10 from the BSgenome object into a usable format. You don’t really need to know whats going on here just run the following commands: mm10_chr10 &lt;- as(mm10_genome$chr10, &quot;DNAStringSet&quot;) names(mm10_chr10) &lt;- &quot;chr10&quot; Okay now we’re ready to create the index using the GmapGenome() function which takes the following arguments: genome = The sequence object to index name = a name to save the index as create = indicates whether to create a new index index &lt;- GmapGenome(genome = mm10_chr10, name = &quot;mm10_chr10&quot;, create = TRUE) Next we want known splice-site information to supplement the index with, we’ll get this from the knownGene TxDb. First load the txdb object, extract exons with the exonsBy() accessor function, then filter chromosomes to just get chr10 exons. txdb &lt;- TxDb.Mmusculus.UCSC.mm10.knownGene exons &lt;- exonsBy(txdb) chr10_exons &lt;- keepSeqlevels(exons, &quot;chr10&quot;) We then add this information to the index using the spliceSites() accessor. spliceSites(index, &quot;knownGene&quot;) &lt;- chr10_exons Ok all setup, alignment time! 5.0.3 Aligning Reads Alignment parameters are set as a simple list then passed the mapping function. There’s lots of potential parameters to tweak but lets just go through a few important ones: -m : the maximum penalty score allowed when mapping - for each mismatch, indel or very distant splicing, GSNAP will apply a penalty to the mapping score. This should be adjusted according to read length. gsnap_param &lt;- GsnapParam(genome = index, unique_only = FALSE, suboptimal_levels = 2L, npaths = 10L, novelsplicing = TRUE, splicing = &quot;knownGene&quot;, indel_penalty = 1L, distant_splice_penalty = 1L, clip_overlap = TRUE) Then we (would) just run the alignment like so: Even with just one chromosome this is still pretty slow (~25m) so rather than run it right now we’ll just load some pre-computed values. gsnap_output &lt;- gsnap(input_a = fastq_files[[1]], input_b = fastq_files[[2]], params = gsnap_param) "],
["02.0_resources.html", "6 Resources", " 6 Resources 6.0.1 Reviews RNA-seq best practices - Conesa et al., 2016. Genome Biology. Statistical methods for differential expression - Huang et al. 2015. Cancer Informatics. RNA-seq overview - Wang et al., 2009. Nature Reviews Genetics. 6.0.2 Tool papers STAR Sailfish kallisto Salmon 6.0.3 Tool websites STAR Tophat2 HISAT2 Salmon Kallisto Sailfish 6.0.4 Protocols Mapping read with STAR 6.0.5 Blog &amp; Forum Posts: 6.0.5.1 QC FASTQC duplication plot explanation 6.0.5.2 Aligners Comparing alignment-free and spliced alignment algorithms Unless one specifically requires transcript-level quantification, I would therefore always recommend using gene-level quantification From these simulations, it appears to be far better to use alignment-independent counting and aggregate to the gene level. 6.0.5.3 General Explanation of arguments for SRA-Tools fastq-dump "]
]
